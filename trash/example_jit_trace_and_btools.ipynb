{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af16a6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    src: Tensor,\n",
      "    tgt: Tensor) -> Tensor:\n",
      "  decoder = self.decoder\n",
      "  encoder = self.encoder\n",
      "  _0 = (decoder).forward(tgt, (encoder).forward(src, ), )\n",
      "  return _0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nhandle_expr(ast(self.encoder),\"encoder\")\\n\\nB_var() -> \"self.encoder\"\\n\\ndict_vars = {\\n    \"decoder\" : B_var(self.val = \"self.decoder\",has_node = False),\\n    \"encoder\" : B_var(self.val = \"self.encoder\",has_node = False,[\"encoder\"]),\\n    \"st\" : B_var(self.val = 5)\\n}\\n\\nx = encoder(src)\\n_0 = self.decoder(x)\\n\\n\\ndict_vars = {\\n    \"st\" : B_var(self.val = 5,has_node = False),\\n    \"v\" : B_var(self.val = \"v\",has_node = True, node = B_node(target=\"v\",self.right_part_of_the_code = \"f(5)\",deps={},deps_constants={\"cst0\"}))\\n    \"y\" : B_var(self.val = \"y\",has_node = True,node = B_node(target=\"y\",self.code = \"g(v)\",deps={B_node of v}))\\n    \"fv\" : B_var(self.val = \"fv\",has_node = True,node = B_node(target=\"fv\",self.code = \"p(y)\",deps={B_node of y}))\\n    \"z\" : B_var(has_node=True,node = B_node(target=\"z\",self.code= \"z = h(fv)\",deps = {B_node of fv}))\\n\\n    \"y\" : B_var of v\\n}\\n\\nst = 5\\nv = f(st)\\ny = v\\nz = h(p(y))\\nhandle(\"v\",\"y\")\\nhandle_expr(\"h(p(y))\",\"z\")\\n\\nhandle_expr(\"y\",\"fv\")\\n\\n\\n\\nhandle(\"ops.prim.Tensor(\\'expr\\')\",\"v\") = handle_expr(\"\\'expr\\'\",\"v\")\\n\\n\\n\\nhandle(\"torch.add(expr1,expr2,expr3,dtype=4)\",\"v\")\\n\\n\\ntorch.add\\ntorch.nn.function.continuous\\ntorch.unet \\ntorch.embedding\\n\\nx.shape()\\n\\ntorch.fft(x)\\n\\n\\nhandle(\"expr1\",\"fv1\") -> B_var(self.val=\"fv1\",has_node=True,node=...)\\n\\n\\n\\nwpe = self.wpe\\nlayers = wpe.layers\\nh = layers[0]\\n\\n\\ndict_vars \\n\"h\" : B_var(self.val = \"self.wpe.layers[0]\",path_from_self=[\"wpe\",\"layers\",\"0\"])\\n\\njit_output.wpe.layers[0].code\\n\\n\\n\\nhandle_expr(\"(norm).forward((_0).forward(src, ), )\",\"_0\")\\n-> B_var(node=B_node(code=\"_0 = linear(fv5)\"))\\n\\n\\nx = f(y)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "mod_transfo = nn.Transformer(nhead=16, num_encoder_layers=1)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((10, 32, 512))\n",
    "\n",
    "script_transfo = torch.jit.trace_module(mod_transfo, {'forward': (src,tgt)},check_trace=False)\n",
    "\n",
    "print(script_transfo.code)\n",
    "\n",
    "\"\"\"\n",
    "handle_expr(ast(self.encoder),\"encoder\")\n",
    "\n",
    "B_var() -> \"self.encoder\"\n",
    "\n",
    "dict_vars = {\n",
    "    \"decoder\" : B_var(self.val = \"self.decoder\",has_node = False),\n",
    "    \"encoder\" : B_var(self.val = \"self.encoder\",has_node = False,[\"encoder\"]),\n",
    "    \"st\" : B_var(self.val = 5)\n",
    "}\n",
    "\n",
    "x = encoder(src)\n",
    "_0 = self.decoder(x)\n",
    "\n",
    "\n",
    "dict_vars = {\n",
    "    \"st\" : B_var(self.val = 5,has_node = False),\n",
    "    \"v\" : B_var(self.val = \"v\",has_node = True, node = B_node(target=\"v\",self.right_part_of_the_code = \"f(5)\",deps={},deps_constants={\"cst0\"}))\n",
    "    \"y\" : B_var(self.val = \"y\",has_node = True,node = B_node(target=\"y\",self.code = \"g(v)\",deps={B_node of v}))\n",
    "    \"fv\" : B_var(self.val = \"fv\",has_node = True,node = B_node(target=\"fv\",self.code = \"p(y)\",deps={B_node of y}))\n",
    "    \"z\" : B_var(has_node=True,node = B_node(target=\"z\",self.code= \"z = h(fv)\",deps = {B_node of fv}))\n",
    "\n",
    "    \"y\" : B_var of v\n",
    "}\n",
    "\n",
    "st = 5\n",
    "v = f(st)\n",
    "y = v\n",
    "z = h(p(y))\n",
    "handle(\"v\",\"y\")\n",
    "handle_expr(\"h(p(y))\",\"z\")\n",
    "\n",
    "handle_expr(\"y\",\"fv\")\n",
    "\n",
    "\n",
    "\n",
    "handle(\"ops.prim.Tensor('expr')\",\"v\") = handle_expr(\"'expr'\",\"v\")\n",
    "\n",
    "\n",
    "\n",
    "handle(\"torch.add(expr1,expr2,expr3,dtype=4)\",\"v\")\n",
    "\n",
    "\n",
    "torch.add\n",
    "torch.nn.function.continuous\n",
    "torch.unet \n",
    "torch.embedding\n",
    "\n",
    "x.shape()\n",
    "\n",
    "torch.fft(x)\n",
    "\n",
    "\n",
    "handle(\"expr1\",\"fv1\") -> B_var(self.val=\"fv1\",has_node=True,node=...)\n",
    "\n",
    "\n",
    "\n",
    "wpe = self.wpe\n",
    "layers = wpe.layers\n",
    "h = layers[0]\n",
    "\n",
    "\n",
    "dict_vars \n",
    "\"h\" : B_var(self.val = \"self.wpe.layers[0]\",path_from_self=[\"wpe\",\"layers\",\"0\"])\n",
    "\n",
    "jit_output.wpe.layers[0].code\n",
    "\n",
    "\n",
    "\n",
    "handle_expr(\"(norm).forward((_0).forward(src, ), )\",\"_0\")\n",
    "-> B_var(node=B_node(code=\"_0 = linear(fv5)\"))\n",
    "\n",
    "\n",
    "x = f(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d8c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    src: Tensor) -> Tensor:\n",
      "  norm = self.norm\n",
      "  layers = self.layers\n",
      "  _0 = getattr(layers, \"0\")\n",
      "  return (norm).forward((_0).forward(src, ), )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(script_transfo.encoder.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df941c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "    body=[\n",
      "        FunctionDef(\n",
      "            name='forward',\n",
      "            args=arguments(\n",
      "                posonlyargs=[],\n",
      "                args=[\n",
      "                    arg(arg='self'),\n",
      "                    arg(\n",
      "                        arg='src',\n",
      "                        annotation=Name(id='Tensor', ctx=Load()))],\n",
      "                kwonlyargs=[],\n",
      "                kw_defaults=[],\n",
      "                defaults=[]),\n",
      "            body=[\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='norm2', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='norm2',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='dropout2', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='dropout2',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='linear2', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='linear2',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='dropout', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='dropout',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='linear1', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='linear1',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='norm1', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='norm1',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='dropout1', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='dropout1',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='self_attn', ctx=Store())],\n",
      "                    value=Attribute(\n",
      "                        value=Name(id='self', ctx=Load()),\n",
      "                        attr='self_attn',\n",
      "                        ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='_0', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='dropout1', ctx=Load()),\n",
      "                            attr='forward',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Call(\n",
      "                                func=Attribute(\n",
      "                                    value=Name(id='self_attn', ctx=Load()),\n",
      "                                    attr='forward',\n",
      "                                    ctx=Load()),\n",
      "                                args=[\n",
      "                                    Name(id='src', ctx=Load())],\n",
      "                                keywords=[])],\n",
      "                        keywords=[])),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='input', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='torch', ctx=Load()),\n",
      "                            attr='add',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='src', ctx=Load()),\n",
      "                            Name(id='_0', ctx=Load())],\n",
      "                        keywords=[])),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='_1', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='norm1', ctx=Load()),\n",
      "                            attr='forward',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='input', ctx=Load())],\n",
      "                        keywords=[])),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='input0', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='torch', ctx=Load()),\n",
      "                            attr='relu',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Call(\n",
      "                                func=Attribute(\n",
      "                                    value=Name(id='linear1', ctx=Load()),\n",
      "                                    attr='forward',\n",
      "                                    ctx=Load()),\n",
      "                                args=[\n",
      "                                    Name(id='_1', ctx=Load())],\n",
      "                                keywords=[])],\n",
      "                        keywords=[])),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='_2', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='linear2', ctx=Load()),\n",
      "                            attr='forward',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Call(\n",
      "                                func=Attribute(\n",
      "                                    value=Name(id='dropout', ctx=Load()),\n",
      "                                    attr='forward',\n",
      "                                    ctx=Load()),\n",
      "                                args=[\n",
      "                                    Name(id='input0', ctx=Load())],\n",
      "                                keywords=[])],\n",
      "                        keywords=[])),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='input1', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='torch', ctx=Load()),\n",
      "                            attr='add',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='_1', ctx=Load()),\n",
      "                            Call(\n",
      "                                func=Attribute(\n",
      "                                    value=Name(id='dropout2', ctx=Load()),\n",
      "                                    attr='forward',\n",
      "                                    ctx=Load()),\n",
      "                                args=[\n",
      "                                    Name(id='_2', ctx=Load())],\n",
      "                                keywords=[])],\n",
      "                        keywords=[])),\n",
      "                Return(\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='norm2', ctx=Load()),\n",
      "                            attr='forward',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='input1', ctx=Load())],\n",
      "                        keywords=[]))],\n",
      "            decorator_list=[],\n",
      "            returns=Name(id='Tensor', ctx=Load()))],\n",
      "    type_ignores=[])\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "print(ast.dump(ast.parse(getattr(script_transfo.encoder.layers,\"0\").code),indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc99455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    query: Tensor,\n",
      "    key: Tensor,\n",
      "    value: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  out_proj = self.out_proj\n",
      "  bias = out_proj.bias\n",
      "  out_proj0 = self.out_proj\n",
      "  weight = out_proj0.weight\n",
      "  in_proj_bias = self.in_proj_bias\n",
      "  in_proj_weight = self.in_proj_weight\n",
      "  tgt_len = ops.prim.NumToTensor(torch.size(query, 0))\n",
      "  _0 = int(tgt_len)\n",
      "  _1 = int(tgt_len)\n",
      "  _2 = int(tgt_len)\n",
      "  bsz = ops.prim.NumToTensor(torch.size(query, 1))\n",
      "  _3 = int(bsz)\n",
      "  _4 = int(bsz)\n",
      "  embed_dim = ops.prim.NumToTensor(torch.size(query, 2))\n",
      "  _5 = int(embed_dim)\n",
      "  head_dim = torch.div(embed_dim, CONSTANTS.c0, rounding_mode=\"trunc\")\n",
      "  _6 = int(head_dim)\n",
      "  _7 = int(head_dim)\n",
      "  _8 = int(head_dim)\n",
      "  w_q, w_k, w_v, = torch.chunk(in_proj_weight, 3)\n",
      "  b_q, b_k, b_v, = torch.chunk(in_proj_bias, 3)\n",
      "  q = torch.linear(query, w_q, b_q)\n",
      "  k = torch.linear(key, w_k, b_k)\n",
      "  v = torch.linear(value, w_v, b_v)\n",
      "  q0 = torch.contiguous(q)\n",
      "  _9 = [_2, int(torch.mul(bsz, CONSTANTS.c0)), _8]\n",
      "  q1 = torch.transpose(torch.view(q0, _9), 0, 1)\n",
      "  k0 = torch.contiguous(k)\n",
      "  _10 = ops.prim.NumToTensor(torch.size(k0, 0))\n",
      "  _11 = [int(_10), int(torch.mul(bsz, CONSTANTS.c0)), _7]\n",
      "  k1 = torch.transpose(torch.view(k0, _11), 0, 1)\n",
      "  v0 = torch.contiguous(v)\n",
      "  _12 = ops.prim.NumToTensor(torch.size(v0, 0))\n",
      "  _13 = [int(_12), int(torch.mul(bsz, CONSTANTS.c0)), _6]\n",
      "  v1 = torch.transpose(torch.view(v0, _13), 0, 1)\n",
      "  src_len = ops.prim.NumToTensor(torch.size(k1, 1))\n",
      "  _14 = int(src_len)\n",
      "  q2 = torch.div(q1, CONSTANTS.c1)\n",
      "  input = torch.bmm(q2, torch.transpose(k1, -2, -1))\n",
      "  input0 = torch.softmax(input, -1)\n",
      "  attn = torch.dropout(input0, 0.10000000000000001, True)\n",
      "  attn_output = torch.bmm(attn, v1)\n",
      "  _15 = torch.contiguous(torch.transpose(attn_output, 0, 1))\n",
      "  attn_output0 = torch.view(_15, [_1, _4, _5])\n",
      "  _16 = torch.linear(attn_output0, weight, bias)\n",
      "  attn_output_weights = torch.view(attn, [_3, 16, _0, _14])\n",
      "  _17 = torch.div(torch.sum(attn_output_weights, [1]), CONSTANTS.c0)\n",
      "  return (_16, _17)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod_attn = mod_lbl0.self_attn\n",
    "\n",
    "script_attn = torch.jit.trace_module(mod_attn, {'forward': (src,src,src,)},check_trace=False)\n",
    "print(script_attn.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59900a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _0 = torch.dropout(input, 0.10000000000000001, True)\n",
      "  return _0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod_dp1 = mod_lbl0.dropout1\n",
    "\n",
    "script_dp1 = torch.jit.trace_module(mod_dp1, {'forward': (src,)},check_trace=False)\n",
    "print(script_dp1.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb888e",
   "metadata": {},
   "source": [
    "# =====================================\n",
    "# FX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "639a6fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, src : torch.Tensor, src_mask : typing_Union[torch.Tensor,NoneType] = None, src_key_padding_mask : typing_Union[torch.Tensor,NoneType] = None) -> torch.Tensor:\n",
      "    self_attn = self.self_attn(src, src, src, attn_mask = src_mask, key_padding_mask = src_key_padding_mask, need_weights = False);  src_mask = src_key_padding_mask = None\n",
      "    getitem = self_attn[0];  self_attn = None\n",
      "    dropout1 = self.dropout1(getitem);  getitem = None\n",
      "    add = src + dropout1;  src = dropout1 = None\n",
      "    norm1 = self.norm1(add);  add = None\n",
      "    linear1 = self.linear1(norm1)\n",
      "    relu = torch.nn.functional.relu(linear1, inplace = False);  linear1 = None\n",
      "    dropout = self.dropout(relu);  relu = None\n",
      "    linear2 = self.linear2(dropout);  dropout = None\n",
      "    dropout2 = self.dropout2(linear2);  linear2 = None\n",
      "    add_1 = norm1 + dropout2;  norm1 = dropout2 = None\n",
      "    norm2 = self.norm2(add_1);  add_1 = None\n",
      "    return norm2\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch.fx import symbolic_trace\n",
    "\n",
    "fx_lbl0 = symbolic_trace(mod_lbl0)\n",
    "print(fx_lbl0.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f48acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def forward(self, query : torch.Tensor, key : torch.Tensor, value : torch.Tensor, key_padding_mask : typing_Union[torch.Tensor,NoneType] = None, need_weights : bool = True, attn_mask : typing_Union[torch.Tensor,NoneType] = None, average_attn_weights : bool = True) -> typing_Tuple[torch.Tensor,typing_Union[torch.Tensor,NoneType]]:\n",
      "    dim = query.dim()\n",
      "    eq = dim == 3;  dim = None\n",
      "    in_proj_weight = self.in_proj_weight\n",
      "    in_proj_bias = self.in_proj_bias\n",
      "    out_proj_weight = self.out_proj.weight\n",
      "    out_proj_bias = self.out_proj.bias\n",
      "    multi_head_attention_forward = torch.nn.functional.multi_head_attention_forward(query, key, value, 512, 16, in_proj_weight, in_proj_bias, None, None, False, 0.1, out_proj_weight, out_proj_bias, training = True, key_padding_mask = key_padding_mask, need_weights = need_weights, attn_mask = attn_mask, use_separate_proj_weight = False, q_proj_weight = None, k_proj_weight = None, v_proj_weight = None, static_k = None, static_v = None);  query = key = value = in_proj_weight = in_proj_bias = out_proj_weight = out_proj_bias = key_padding_mask = need_weights = attn_mask = None\n",
      "    getitem = multi_head_attention_forward[0]\n",
      "    getitem_1 = multi_head_attention_forward[1];  multi_head_attention_forward = None\n",
      "    return (getitem, getitem_1)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "fx_attn = symbolic_trace(mod_attn)\n",
    "print(fx_attn.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a104249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__builtins__', '__call__', '__class__', '__closure__', '__code__', '__defaults__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__get__', '__getattribute__', '__globals__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__kwdefaults__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__']\n",
      "PythonCode(src='\\n\\n\\ndef forward(self, query : torch.Tensor, key : torch.Tensor, value : torch.Tensor, embed_dim_to_check : int, num_heads : int, in_proj_weight : torch.Tensor, in_proj_bias : typing_Union[torch.Tensor,NoneType], bias_k : typing_Union[torch.Tensor,NoneType], bias_v : typing_Union[torch.Tensor,NoneType], add_zero_attn : bool, dropout_p : float, out_proj_weight : torch.Tensor, out_proj_bias : typing_Union[torch.Tensor,NoneType], training : bool = True, key_padding_mask : typing_Union[torch.Tensor,NoneType] = None, need_weights : bool = True, attn_mask : typing_Union[torch.Tensor,NoneType] = None, use_separate_proj_weight : bool = False, q_proj_weight : typing_Union[torch.Tensor,NoneType] = None, k_proj_weight : typing_Union[torch.Tensor,NoneType] = None, v_proj_weight : typing_Union[torch.Tensor,NoneType] = None, static_k : typing_Union[torch.Tensor,NoneType] = None, static_v : typing_Union[torch.Tensor,NoneType] = None, average_attn_weights : bool = True) -> typing_Tuple[torch.Tensor,typing_Union[torch.Tensor,NoneType]]:\\n    multi_head_attention_forward = torch.nn.functional.multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training = training, key_padding_mask = key_padding_mask, need_weights = need_weights, attn_mask = attn_mask, use_separate_proj_weight = use_separate_proj_weight, q_proj_weight = q_proj_weight, k_proj_weight = k_proj_weight, v_proj_weight = v_proj_weight, static_k = static_k, static_v = static_v);  query = key = value = embed_dim_to_check = num_heads = in_proj_weight = in_proj_bias = bias_k = bias_v = add_zero_attn = dropout_p = out_proj_weight = out_proj_bias = training = key_padding_mask = need_weights = attn_mask = use_separate_proj_weight = q_proj_weight = k_proj_weight = v_proj_weight = static_k = static_v = None\\n    return multi_head_attention_forward\\n    ', globals={'inf': inf, 'nan': nan, 'NoneType': <class 'NoneType'>, 'torch': <module 'torch' from '/home/theotime/.local/lib/python3.10/site-packages/torch/__init__.py'>, 'device': <class 'torch.device'>, 'fx_pytree': <module 'torch.fx._pytree' from '/home/theotime/.local/lib/python3.10/site-packages/torch/fx/_pytree.py'>, 'pytree': <module 'torch.utils._pytree' from '/home/theotime/.local/lib/python3.10/site-packages/torch/utils/_pytree.py'>, 'int': <class 'int'>, 'typing_Union': typing.Union, 'bool': <class 'bool'>, 'float': <class 'float'>, 'typing_Tuple': typing.Tuple})\n"
     ]
    }
   ],
   "source": [
    "print(dir(torch.nn.functional.multi_head_attention_forward))\n",
    "\n",
    "fx_multi = symbolic_trace(torch.nn.functional.multi_head_attention_forward)\n",
    "print(fx_multi.graph.python_code(fx_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f364862",
   "metadata": {},
   "source": [
    "## Fx fails....can't open any built-in functions \n",
    "symbolic_trace(torch.nn.functional.multi_head_attention_forward)\n",
    "= torch.nn.functional.multi_head_attention_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c1dad",
   "metadata": {},
   "source": [
    "# Correction de jit.trace_module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b05557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential (\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,512),\n",
    "        )\n",
    "    \n",
    "    def forward(self,p1,p2,p3):\n",
    "        y1 = self.linear_stack(p1)\n",
    "        y2 = self.linear_stack(p2)\n",
    "        y3 = self.linear_stack(p3)\n",
    "        return (y1+y2,y1-y2+y3,y1)\n",
    "\n",
    "class MyMod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.op = SubMod()\n",
    "    def forward(self,x):\n",
    "        (z1,z2,z3) = self.op(x,-x,x)\n",
    "        return z1 + 2*z3\n",
    "\n",
    "mymod = MyMod()\n",
    "\n",
    "#fx_mymod = symbolic_trace(mymod)\n",
    "#print(fx_mymod.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e276fc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== MYMOD =====\n",
      "graph(%self.1 : __torch__.___torch_mangle_161.MyMod,\n",
      "      %x : Float(128, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %op : __torch__.___torch_mangle_160.SubMod = prim::GetAttr[name=\"op\"](%self.1)\n",
      "  %input.3 : Float(128, strides=[1], requires_grad=0, device=cpu) = aten::neg(%x) # /tmp/ipykernel_115045/3696616435.py:24:0\n",
      "  %74 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%op, %x, %input.3)\n",
      "  %72 : Float(512, strides=[1], requires_grad=1, device=cpu), %73 : Float(512, strides=[1], requires_grad=1, device=cpu) = prim::TupleUnpack(%74)\n",
      "  %31 : Long(requires_grad=0, device=cpu) = prim::Constant[value={2}]() # /tmp/ipykernel_115045/3696616435.py:24:0\n",
      "  %32 : Float(512, strides=[1], requires_grad=1, device=cpu) = aten::mul(%72, %31) # /tmp/ipykernel_115045/3696616435.py:24:0\n",
      "  %33 : int = prim::Constant[value=1]() # /tmp/ipykernel_115045/3696616435.py:24:0\n",
      "  %34 : Float(512, strides=[1], requires_grad=1, device=cpu) = aten::add(%73, %32, %33) # /tmp/ipykernel_115045/3696616435.py:24:0\n",
      "  return (%34)\n",
      "\n",
      "===== SUBMOD : op =====\n",
      "def forward(self,\n",
      "    p1: Tensor,\n",
      "    p2: Tensor,\n",
      "    p3: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
      "  linear_stack = self.linear_stack\n",
      "  _0 = (linear_stack).forward(p1, )\n",
      "  _1 = (linear_stack).forward1(p2, )\n",
      "  _2 = (linear_stack).forward2(p3, )\n",
      "  _3 = (torch.add(_0, _1), torch.add(torch.sub(_0, _1), _2), _0)\n",
      "  return _3\n",
      "\n",
      "===== USING SCRIPT =====\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  op = self.op\n",
      "  z1, z2, z3, = (op).forward(x, torch.neg(x), x, )\n",
      "  return torch.add(z1, torch.mul(z3, 2))\n",
      "\n",
      "===== USING FX =====\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    neg = -x\n",
      "    op_linear_stack_0 = getattr(self.op.linear_stack, \"0\")(x)\n",
      "    op_linear_stack_1 = getattr(self.op.linear_stack, \"1\")(op_linear_stack_0);  op_linear_stack_0 = None\n",
      "    op_linear_stack_2 = getattr(self.op.linear_stack, \"0\")(neg);  neg = None\n",
      "    op_linear_stack_3 = getattr(self.op.linear_stack, \"1\")(op_linear_stack_2);  op_linear_stack_2 = None\n",
      "    op_linear_stack_4 = getattr(self.op.linear_stack, \"0\")(x);  x = None\n",
      "    op_linear_stack_5 = getattr(self.op.linear_stack, \"1\")(op_linear_stack_4);  op_linear_stack_4 = None\n",
      "    add = op_linear_stack_1 + op_linear_stack_3\n",
      "    sub = op_linear_stack_1 - op_linear_stack_3;  op_linear_stack_3 = None\n",
      "    add_1 = sub + op_linear_stack_5;  sub = op_linear_stack_5 = None\n",
      "    mul = 2 * op_linear_stack_1;  op_linear_stack_1 = None\n",
      "    add_2 = add + mul;  add = mul = None\n",
      "    return add_2\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "src_mymod = torch.rand((128))\n",
    "script_mymod = torch.jit.trace_module(mymod, {'forward': (src_mymod,)},check_trace=False)\n",
    "print(\"===== MYMOD =====\")\n",
    "print(script_mymod.graph)\n",
    "\n",
    "mod_op = mymod.op\n",
    "script_op = torch.jit.trace_module(mod_op, {'forward': (src_mymod,-src_mymod,src_mymod)},check_trace=False)\n",
    "print(\"===== SUBMOD : op =====\")\n",
    "print(script_op.code)\n",
    "\n",
    "#x = torch.rand((128))\n",
    "#print(x-0.5)\n",
    "#print(script_mymod(x-0.5))\n",
    "\n",
    "script_mm = torch.jit.script(mymod)\n",
    "print(\"===== USING SCRIPT =====\")\n",
    "print(script_mm.code)\n",
    "\n",
    "print(\"===== USING FX =====\")\n",
    "fx_mymod = symbolic_trace(mymod)\n",
    "print(fx_mymod.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d891685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def multi_head_attention_forward(query: Tensor,\n",
      "    key: Tensor,\n",
      "    value: Tensor,\n",
      "    embed_dim_to_check: int,\n",
      "    num_heads: int,\n",
      "    in_proj_weight: Tensor,\n",
      "    in_proj_bias: Optional[Tensor],\n",
      "    bias_k: Optional[Tensor],\n",
      "    bias_v: Optional[Tensor],\n",
      "    add_zero_attn: bool,\n",
      "    dropout_p: float,\n",
      "    out_proj_weight: Tensor,\n",
      "    out_proj_bias: Optional[Tensor],\n",
      "    training: bool=True,\n",
      "    key_padding_mask: Optional[Tensor]=None,\n",
      "    need_weights: bool=True,\n",
      "    attn_mask: Optional[Tensor]=None,\n",
      "    use_separate_proj_weight: bool=False,\n",
      "    q_proj_weight: Optional[Tensor]=None,\n",
      "    k_proj_weight: Optional[Tensor]=None,\n",
      "    v_proj_weight: Optional[Tensor]=None,\n",
      "    static_k: Optional[Tensor]=None,\n",
      "    static_v: Optional[Tensor]=None,\n",
      "    average_attn_weights: bool=True) -> Tuple[Tensor, Optional[Tensor]]:\n",
      "  _0 = __torch__.torch.nn.functional._mha_shape_check\n",
      "  _1 = \"was expecting embedding dimension of {}, but got {}\"\n",
      "  _2 = \"embed_dim {} not divisible by num_heads {}\"\n",
      "  _3 = \"key\\'s sequence and batch dims {} do not match value\\'s {}\"\n",
      "  _4 = \"key shape {} does not match value shape {}\"\n",
      "  _5 = __torch__.torch.nn.functional._in_projection_packed\n",
      "  _6 = \"AssertionError: use_separate_proj_weight is True but q_proj_weight is None\"\n",
      "  _7 = \"AssertionError: use_separate_proj_weight is True but k_proj_weight is None\"\n",
      "  _8 = \"AssertionError: use_separate_proj_weight is True but v_proj_weight is None\"\n",
      "  _9 = __torch__.torch.nn.functional._in_projection\n",
      "  _10 = \"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\"\n",
      "  _11 = \"Only float, byte, and bool types are supported for attn_mask, not {}\"\n",
      "  _12 = \"The shape of the 2D attn_mask is {}, but should be {}.\"\n",
      "  _13 = \"The shape of the 3D attn_mask is {}, but should be {}.\"\n",
      "  _14 = \"attn_mask\\'s dimension {} is not supported\"\n",
      "  _15 = \"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\"\n",
      "  _16 = \"AssertionError: bias cannot be added to static key.\"\n",
      "  _17 = \"AssertionError: bias cannot be added to static value.\"\n",
      "  _18 = \"expecting static_k.size(0) of {}, but got {}\"\n",
      "  _19 = \"expecting static_k.size(2) of {}, but got {}\"\n",
      "  _20 = \"expecting static_v.size(0) of {}, but got {}\"\n",
      "  _21 = \"expecting static_v.size(2) of {}, but got {}\"\n",
      "  _22 = \"expecting key_padding_mask shape of {}, but got {}\"\n",
      "  _23 = __torch__.torch.nn.functional._scaled_dot_product_attention\n",
      "  _24 = uninitialized(Optional[Tensor])\n",
      "  _25 = uninitialized(Optional[Tensor])\n",
      "  _26 = uninitialized(Tensor)\n",
      "  is_batched = _0(query, key, value, key_padding_mask, attn_mask, num_heads, )\n",
      "  if torch.__not__(is_batched):\n",
      "    query1 = torch.unsqueeze(query, 1)\n",
      "    key1 = torch.unsqueeze(key, 1)\n",
      "    value1 = torch.unsqueeze(value, 1)\n",
      "    _27 = torch.__isnot__(key_padding_mask, None)\n",
      "    if _27:\n",
      "      key_padding_mask2 = unchecked_cast(Tensor, key_padding_mask)\n",
      "      key_padding_mask3 = torch.unsqueeze(key_padding_mask2, 0)\n",
      "      key_padding_mask1 : Optional[Tensor] = key_padding_mask3\n",
      "    else:\n",
      "      key_padding_mask1 = key_padding_mask\n",
      "    query0, key0, value0, key_padding_mask0 = query1, key1, value1, key_padding_mask1\n",
      "  else:\n",
      "    query0, key0, value0, key_padding_mask0 = query, key, value, key_padding_mask\n",
      "  tgt_len, bsz, embed_dim, = torch.size(query0)\n",
      "  src_len, _28, _29, = torch.size(key0)\n",
      "  _30 = torch.eq(embed_dim, embed_dim_to_check)\n",
      "  if _30:\n",
      "    pass\n",
      "  else:\n",
      "    _31 = torch.format(_1, embed_dim_to_check, embed_dim)\n",
      "    ops.prim.RaiseException(torch.add(\"AssertionError: \", _31))\n",
      "  embed_dim0 = unchecked_cast(int, embed_dim)\n",
      "  head_dim = torch.floordiv(embed_dim0, num_heads)\n",
      "  _32 = torch.eq(torch.mul(head_dim, num_heads), embed_dim0)\n",
      "  if _32:\n",
      "    pass\n",
      "  else:\n",
      "    _33 = torch.format(_2, embed_dim0, num_heads)\n",
      "    ops.prim.RaiseException(torch.add(\"AssertionError: \", _33))\n",
      "  if use_separate_proj_weight:\n",
      "    _34 = torch.slice(torch.size(key0), None, 2)\n",
      "    _35 = torch.slice(torch.size(value0), None, 2)\n",
      "    if torch.eq(_34, _35):\n",
      "      pass\n",
      "    else:\n",
      "      _36 = torch.slice(torch.size(key0), None, 2)\n",
      "      _37 = torch.slice(torch.size(value0), None, 2)\n",
      "      _38 = torch.add(\"AssertionError: \", torch.format(_3, _36, _37))\n",
      "      ops.prim.RaiseException(_38)\n",
      "  else:\n",
      "    _39 = torch.eq(torch.size(key0), torch.size(value0))\n",
      "    if _39:\n",
      "      pass\n",
      "    else:\n",
      "      _40 = torch.format(_4, torch.size(key0), torch.size(value0))\n",
      "      _41 = torch.add(\"AssertionError: \", _40)\n",
      "      ops.prim.RaiseException(_41)\n",
      "  _42 = torch.__not__(use_separate_proj_weight)\n",
      "  if _42:\n",
      "    _43 = _5(query0, key0, value0, in_proj_weight, in_proj_bias, )\n",
      "    q0, k0, v0, = _43\n",
      "    k, v, q = k0, v0, q0\n",
      "  else:\n",
      "    _44 = torch.__isnot__(q_proj_weight, None)\n",
      "    if _44:\n",
      "      q_proj_weight1 = unchecked_cast(Tensor, q_proj_weight)\n",
      "      q_proj_weight0 = q_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_6)\n",
      "      q_proj_weight0 = _26\n",
      "    _45 = torch.__isnot__(k_proj_weight, None)\n",
      "    if _45:\n",
      "      k_proj_weight1 = unchecked_cast(Tensor, k_proj_weight)\n",
      "      k_proj_weight0 = k_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_7)\n",
      "      k_proj_weight0 = _26\n",
      "    _46 = torch.__isnot__(v_proj_weight, None)\n",
      "    if _46:\n",
      "      v_proj_weight1 = unchecked_cast(Tensor, v_proj_weight)\n",
      "      v_proj_weight0 = v_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_8)\n",
      "      v_proj_weight0 = _26\n",
      "    if torch.__is__(in_proj_bias, None):\n",
      "      b_q, b_k, b_v = None, None, None\n",
      "    else:\n",
      "      in_proj_bias0 = unchecked_cast(Tensor, in_proj_bias)\n",
      "      b_q0, b_k0, b_v0, = torch.chunk(in_proj_bias0, 3)\n",
      "      b_q, b_k, b_v = b_q0, b_k0, b_v0\n",
      "    _47 = _9(query0, key0, value0, q_proj_weight0, k_proj_weight0, v_proj_weight0, b_q, b_k, b_v, )\n",
      "    q1, k1, v1, = _47\n",
      "    k, v, q = k1, v1, q1\n",
      "  if torch.__isnot__(attn_mask, None):\n",
      "    attn_mask1 = unchecked_cast(Tensor, attn_mask)\n",
      "    _48 = torch.eq(ops.prim.dtype(attn_mask1), 0)\n",
      "    if _48:\n",
      "      torch.warn(_10)\n",
      "      attn_mask2 = torch.to(attn_mask1, 11)\n",
      "    else:\n",
      "      _49 = torch.is_floating_point(attn_mask1)\n",
      "      if _49:\n",
      "        _50 = True\n",
      "      else:\n",
      "        _51 = torch.eq(ops.prim.dtype(attn_mask1), 11)\n",
      "        _50 = _51\n",
      "      if _50:\n",
      "        pass\n",
      "      else:\n",
      "        _52 = torch.format(_11, ops.prim.dtype(attn_mask1))\n",
      "        _53 = torch.add(\"AssertionError: \", _52)\n",
      "        ops.prim.RaiseException(_53)\n",
      "      attn_mask2 = attn_mask1\n",
      "    if torch.eq(torch.dim(attn_mask2), 2):\n",
      "      correct_2d_size = (tgt_len, src_len)\n",
      "      _54 = torch.ne(torch.size(attn_mask2), [tgt_len, src_len])\n",
      "      if _54:\n",
      "        _55 = torch.format(_12, torch.size(attn_mask2), correct_2d_size)\n",
      "        ops.prim.RaiseException(_55)\n",
      "      else:\n",
      "        pass\n",
      "      attn_mask3 = torch.unsqueeze(attn_mask2, 0)\n",
      "    else:\n",
      "      _56 = torch.eq(torch.dim(attn_mask2), 3)\n",
      "      if _56:\n",
      "        _57 = torch.mul(bsz, num_heads)\n",
      "        correct_3d_size = (_57, tgt_len, src_len)\n",
      "        _58 = torch.ne(torch.size(attn_mask2), [_57, tgt_len, src_len])\n",
      "        if _58:\n",
      "          _59 = torch.format(_13, torch.size(attn_mask2), correct_3d_size)\n",
      "          ops.prim.RaiseException(_59)\n",
      "        else:\n",
      "          pass\n",
      "      else:\n",
      "        _60 = torch.format(_14, torch.dim(attn_mask2))\n",
      "        ops.prim.RaiseException(_60)\n",
      "      attn_mask3 = attn_mask2\n",
      "    attn_mask0 : Optional[Tensor] = attn_mask3\n",
      "  else:\n",
      "    attn_mask0 = attn_mask\n",
      "  _61 = torch.__isnot__(key_padding_mask0, None)\n",
      "  if _61:\n",
      "    key_padding_mask5 = unchecked_cast(Tensor, key_padding_mask0)\n",
      "    _63 = torch.eq(ops.prim.dtype(key_padding_mask5), 0)\n",
      "    _62, key_padding_mask4 = _63, key_padding_mask5\n",
      "  else:\n",
      "    _62, key_padding_mask4 = False, key_padding_mask0\n",
      "  if _62:\n",
      "    key_padding_mask7 = unchecked_cast(Tensor, key_padding_mask4)\n",
      "    torch.warn(_15)\n",
      "    key_padding_mask6 : Optional[Tensor] = torch.to(key_padding_mask7, 11)\n",
      "  else:\n",
      "    key_padding_mask6 = key_padding_mask4\n",
      "  if torch.__isnot__(bias_k, None):\n",
      "    bias_k1 = unchecked_cast(Tensor, bias_k)\n",
      "    _64, bias_k0 = torch.__isnot__(bias_v, None), bias_k1\n",
      "  else:\n",
      "    _64, bias_k0 = False, bias_k\n",
      "  if _64:\n",
      "    bias_k2 = unchecked_cast(Tensor, bias_k0)\n",
      "    bias_v0 = unchecked_cast(Tensor, bias_v)\n",
      "    if torch.__is__(static_k, None):\n",
      "      static_k1 : Optional[Tensor] = static_k\n",
      "    else:\n",
      "      ops.prim.RaiseException(_16)\n",
      "      static_k1 = _25\n",
      "    if torch.__is__(static_v, None):\n",
      "      static_v1 : Optional[Tensor] = static_v\n",
      "    else:\n",
      "      ops.prim.RaiseException(_17)\n",
      "      static_v1 = _24\n",
      "    _65 = [k, torch.repeat(bias_k2, [1, bsz, 1])]\n",
      "    k3 = torch.cat(_65)\n",
      "    _66 = [v, torch.repeat(bias_v0, [1, bsz, 1])]\n",
      "    v3 = torch.cat(_66)\n",
      "    if torch.__isnot__(attn_mask0, None):\n",
      "      attn_mask6 = unchecked_cast(Tensor, attn_mask0)\n",
      "      attn_mask7 = __torch__.torch.nn.functional._pad(attn_mask6, [0, 1], \"constant\", 0., )\n",
      "      attn_mask5 : Optional[Tensor] = attn_mask7\n",
      "    else:\n",
      "      attn_mask5 = attn_mask0\n",
      "    _67 = torch.__isnot__(key_padding_mask6, None)\n",
      "    if _67:\n",
      "      key_padding_mask10 = unchecked_cast(Tensor, key_padding_mask6)\n",
      "      key_padding_mask11 = __torch__.torch.nn.functional._pad(key_padding_mask10, [0, 1], \"constant\", 0., )\n",
      "      key_padding_mask9 : Optional[Tensor] = key_padding_mask11\n",
      "    else:\n",
      "      key_padding_mask9 = key_padding_mask6\n",
      "    static_k0, k2, static_v0, v2, attn_mask4, key_padding_mask8 = static_k1, k3, static_v1, v3, attn_mask5, key_padding_mask9\n",
      "  else:\n",
      "    if torch.__is__(bias_k0, None):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    if torch.__is__(bias_v, None):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    static_k0, k2, static_v0, v2, attn_mask4, key_padding_mask8 = static_k, k, static_v, v, attn_mask0, key_padding_mask6\n",
      "  _68 = torch.contiguous(q)\n",
      "  _69 = [tgt_len, torch.mul(bsz, num_heads), head_dim]\n",
      "  q2 = torch.transpose(torch.view(_68, _69), 0, 1)\n",
      "  if torch.__is__(static_k0, None):\n",
      "    _70 = torch.contiguous(k2)\n",
      "    _71 = [(torch.size(k2))[0], torch.mul(bsz, num_heads), head_dim]\n",
      "    k5 = torch.transpose(torch.view(_70, _71), 0, 1)\n",
      "    k4 = k5\n",
      "  else:\n",
      "    static_k2 = unchecked_cast(Tensor, static_k0)\n",
      "    _72 = torch.eq(torch.size(static_k2, 0), torch.mul(bsz, num_heads))\n",
      "    if _72:\n",
      "      pass\n",
      "    else:\n",
      "      _73 = torch.format(_18, torch.mul(bsz, num_heads), torch.size(static_k2, 0))\n",
      "      _74 = torch.add(\"AssertionError: \", _73)\n",
      "      ops.prim.RaiseException(_74)\n",
      "    _75 = torch.eq(torch.size(static_k2, 2), head_dim)\n",
      "    if _75:\n",
      "      pass\n",
      "    else:\n",
      "      _76 = torch.format(_19, head_dim, torch.size(static_k2, 2))\n",
      "      _77 = torch.add(\"AssertionError: \", _76)\n",
      "      ops.prim.RaiseException(_77)\n",
      "    k4 = static_k2\n",
      "  if torch.__is__(static_v0, None):\n",
      "    _78 = torch.contiguous(v2)\n",
      "    _79 = [(torch.size(v2))[0], torch.mul(bsz, num_heads), head_dim]\n",
      "    v5 = torch.transpose(torch.view(_78, _79), 0, 1)\n",
      "    v4 = v5\n",
      "  else:\n",
      "    static_v2 = unchecked_cast(Tensor, static_v0)\n",
      "    _80 = torch.eq(torch.size(static_v2, 0), torch.mul(bsz, num_heads))\n",
      "    if _80:\n",
      "      pass\n",
      "    else:\n",
      "      _81 = torch.format(_20, torch.mul(bsz, num_heads), torch.size(static_v2, 0))\n",
      "      _82 = torch.add(\"AssertionError: \", _81)\n",
      "      ops.prim.RaiseException(_82)\n",
      "    _83 = torch.eq(torch.size(static_v2, 2), head_dim)\n",
      "    if _83:\n",
      "      pass\n",
      "    else:\n",
      "      _84 = torch.format(_21, head_dim, torch.size(static_v2, 2))\n",
      "      _85 = torch.add(\"AssertionError: \", _84)\n",
      "      ops.prim.RaiseException(_85)\n",
      "    v4 = static_v2\n",
      "  if add_zero_attn:\n",
      "    _86 = torch.mul(bsz, num_heads)\n",
      "    _87 = ops.prim.dtype(k4)\n",
      "    _88 = ops.prim.device(k4)\n",
      "    _89 = torch.zeros([_86, 1, head_dim], dtype=_87, layout=None, device=_88)\n",
      "    k7 = torch.cat([k4, _89], 1)\n",
      "    _90 = ops.prim.dtype(v4)\n",
      "    _91 = ops.prim.device(v4)\n",
      "    _92 = torch.zeros([_86, 1, head_dim], dtype=_90, layout=None, device=_91)\n",
      "    v7 = torch.cat([v4, _92], 1)\n",
      "    if torch.__isnot__(attn_mask4, None):\n",
      "      attn_mask10 = unchecked_cast(Tensor, attn_mask4)\n",
      "      attn_mask11 = __torch__.torch.nn.functional._pad(attn_mask10, [0, 1], \"constant\", 0., )\n",
      "      attn_mask9 : Optional[Tensor] = attn_mask11\n",
      "    else:\n",
      "      attn_mask9 = attn_mask4\n",
      "    _93 = torch.__isnot__(key_padding_mask8, None)\n",
      "    if _93:\n",
      "      key_padding_mask14 = unchecked_cast(Tensor, key_padding_mask8)\n",
      "      key_padding_mask15 = __torch__.torch.nn.functional._pad(key_padding_mask14, [0, 1], \"constant\", 0., )\n",
      "      key_padding_mask13 : Optional[Tensor] = key_padding_mask15\n",
      "    else:\n",
      "      key_padding_mask13 = key_padding_mask8\n",
      "    k6, key_padding_mask12, attn_mask8, v6 = k7, key_padding_mask13, attn_mask9, v7\n",
      "  else:\n",
      "    k6, key_padding_mask12, attn_mask8, v6 = k4, key_padding_mask8, attn_mask4, v4\n",
      "  src_len0 = torch.size(k6, 1)\n",
      "  _94 = torch.__isnot__(key_padding_mask12, None)\n",
      "  if _94:\n",
      "    key_padding_mask16 = unchecked_cast(Tensor, key_padding_mask12)\n",
      "    _95 = torch.eq(torch.size(key_padding_mask16), [bsz, src_len0])\n",
      "    if _95:\n",
      "      pass\n",
      "    else:\n",
      "      _96 = torch.format(_22, (bsz, src_len0), torch.size(key_padding_mask16))\n",
      "      _97 = torch.add(\"AssertionError: \", _96)\n",
      "      ops.prim.RaiseException(_97)\n",
      "    _98 = torch.view(key_padding_mask16, [bsz, 1, 1, src_len0])\n",
      "    _99 = torch.expand(_98, [-1, num_heads, -1, -1])\n",
      "    _100 = [torch.mul(bsz, num_heads), 1, src_len0]\n",
      "    key_padding_mask17 = torch.reshape(_99, _100)\n",
      "    if torch.__is__(attn_mask8, None):\n",
      "      attn_mask13 = key_padding_mask17\n",
      "    else:\n",
      "      attn_mask14 = unchecked_cast(Tensor, attn_mask8)\n",
      "      _101 = torch.eq(ops.prim.dtype(attn_mask14), 11)\n",
      "      if _101:\n",
      "        attn_mask16 = torch.logical_or(attn_mask14, key_padding_mask17)\n",
      "        attn_mask15 = attn_mask16\n",
      "      else:\n",
      "        attn_mask17 = torch.masked_fill(attn_mask14, key_padding_mask17, -inf)\n",
      "        attn_mask15 = attn_mask17\n",
      "      attn_mask13 = attn_mask15\n",
      "    attn_mask12 : Optional[Tensor] = attn_mask13\n",
      "  else:\n",
      "    attn_mask12 = attn_mask8\n",
      "  if torch.__isnot__(attn_mask12, None):\n",
      "    attn_mask19 = unchecked_cast(Tensor, attn_mask12)\n",
      "    _103 = torch.eq(ops.prim.dtype(attn_mask19), 11)\n",
      "    _102, attn_mask18 = _103, attn_mask19\n",
      "  else:\n",
      "    _102, attn_mask18 = False, attn_mask12\n",
      "  if _102:\n",
      "    attn_mask21 = unchecked_cast(Tensor, attn_mask18)\n",
      "    new_attn_mask = torch.zeros_like(attn_mask21, dtype=ops.prim.dtype(q2))\n",
      "    _104 = torch.masked_fill_(new_attn_mask, attn_mask21, -inf)\n",
      "    attn_mask20 : Optional[Tensor] = new_attn_mask\n",
      "  else:\n",
      "    attn_mask20 = attn_mask18\n",
      "  if torch.__not__(training):\n",
      "    dropout_p0 = 0.\n",
      "  else:\n",
      "    dropout_p0 = dropout_p\n",
      "  _105 = _23(q2, k6, v6, attn_mask20, dropout_p0, )\n",
      "  attn_output, attn_output_weights, = _105\n",
      "  _106 = torch.contiguous(torch.transpose(attn_output, 0, 1))\n",
      "  attn_output0 = torch.view(_106, [tgt_len, bsz, embed_dim0])\n",
      "  attn_output1 = torch.linear(attn_output0, out_proj_weight, out_proj_bias)\n",
      "  if need_weights:\n",
      "    attn_output_weights0 = torch.view(attn_output_weights, [bsz, num_heads, tgt_len, src_len0])\n",
      "    if average_attn_weights:\n",
      "      _108 = torch.sum(attn_output_weights0, [1])\n",
      "      attn_output_weights1 = torch.div(_108, num_heads)\n",
      "    else:\n",
      "      attn_output_weights1 = attn_output_weights0\n",
      "    if torch.__not__(is_batched):\n",
      "      attn_output3 = torch.squeeze(attn_output1, 1)\n",
      "      attn_output_weights3 = torch.squeeze(attn_output_weights1, 0)\n",
      "      attn_output2, attn_output_weights2 = attn_output3, attn_output_weights3\n",
      "    else:\n",
      "      attn_output2, attn_output_weights2 = attn_output1, attn_output_weights1\n",
      "    _109 = (attn_output2, attn_output_weights2)\n",
      "    _107 = _109\n",
      "  else:\n",
      "    if torch.__not__(is_batched):\n",
      "      attn_output4 = torch.squeeze(attn_output1, 1)\n",
      "    else:\n",
      "      attn_output4 = attn_output1\n",
      "    _107 = (attn_output4, None)\n",
      "  return _107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim = src.dim()\n",
    "eq = dim == 3;  dim = None\n",
    "in_proj_weight = mod_attn.in_proj_weight\n",
    "in_proj_bias = mod_attn.in_proj_bias\n",
    "out_proj_weight = mod_attn.out_proj.weight\n",
    "out_proj_bias = mod_attn.out_proj.bias\n",
    "#script_mfw = torch.jit.trace(torch.nn.functional.multi_head_attention_forward, (src,src,src, 512, 16,\n",
    "#        in_proj_weight, in_proj_bias, None, None, False, 0.1, out_proj_weight, \n",
    "#        out_proj_bias, True, None, True, \n",
    "#        None, False, None, None, \n",
    "#        None, None, None))\n",
    "script_mfw = torch.jit.script(torch.nn.functional.multi_head_attention_forward)\n",
    "print(script_mfw.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92999e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.nn.functional.multi_head_attention_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cca614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fct = lambda src : torch.nn.functional.multi_head_attention_forward(src,src,src, 512, 16,\n",
    "        in_proj_weight, in_proj_bias, None, None, False, 0.1, out_proj_weight, \n",
    "        out_proj_bias, True, None, True, \n",
    "        None, False, None, None, \n",
    "        None, None, None)\n",
    "print(type(fct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72079515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    src: Tensor) -> Tensor:\n",
      "  norm2 = self.norm2\n",
      "  dropout2 = self.dropout2\n",
      "  linear2 = self.linear2\n",
      "  dropout = self.dropout\n",
      "  linear1 = self.linear1\n",
      "  norm1 = self.norm1\n",
      "  dropout1 = self.dropout1\n",
      "  self_attn = self.self_attn\n",
      "  _0 = (dropout1).forward((self_attn).forward(src, ), )\n",
      "  input = torch.add(src, _0)\n",
      "  _1 = (norm1).forward(input, )\n",
      "  input0 = torch.relu((linear1).forward(_1, ))\n",
      "  _2 = (linear2).forward((dropout).forward(input0, ), )\n",
      "  input1 = torch.add(_1, (dropout2).forward(_2, ))\n",
      "  return (norm2).forward(input1, )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.8165e-02,  3.7026e-01, -3.3944e-01,  ..., -1.9990e+00,\n",
       "           3.2725e-01,  2.4977e-01],\n",
       "         [-1.0117e-01, -9.1124e-01, -1.2135e-01,  ...,  1.3262e-01,\n",
       "          -5.5297e-01, -3.6653e-01],\n",
       "         [-1.0041e+00, -4.2845e-01,  4.0479e-01,  ...,  2.6604e-01,\n",
       "          -7.5349e-01, -9.0121e-01],\n",
       "         ...,\n",
       "         [-1.1341e+00, -1.9409e-01,  4.3642e-01,  ..., -9.8668e-01,\n",
       "           2.3653e-01, -7.7267e-01],\n",
       "         [-5.4976e-01, -1.2877e+00, -5.1683e-01,  ..., -1.9112e+00,\n",
       "           1.8272e-01,  2.0868e-01],\n",
       "         [-1.1528e+00, -5.7536e-01, -1.9265e-01,  ..., -4.4269e-01,\n",
       "           9.4982e-03, -3.4241e-01]],\n",
       "\n",
       "        [[-2.1546e+00,  2.0897e-02, -3.0739e-01,  ..., -1.9809e-01,\n",
       "           2.4649e-01, -1.7629e-01],\n",
       "         [-2.0961e+00, -6.9665e-01, -5.9365e-01,  ..., -1.0587e-03,\n",
       "          -1.0414e+00,  6.5376e-01],\n",
       "         [-3.7291e-01, -1.3615e-01, -4.4357e-01,  ..., -9.7485e-01,\n",
       "          -3.9125e-01,  8.1566e-01],\n",
       "         ...,\n",
       "         [-1.9534e+00, -6.8798e-01, -1.0164e+00,  ..., -1.4274e+00,\n",
       "          -1.2604e+00, -1.3061e+00],\n",
       "         [-8.5080e-01,  8.3765e-01, -7.1748e-01,  ..., -7.4664e-01,\n",
       "          -1.5602e+00, -7.1811e-01],\n",
       "         [-7.0179e-01, -1.9251e+00,  3.7251e-01,  ...,  9.4443e-02,\n",
       "           1.2588e+00, -2.5895e-01]],\n",
       "\n",
       "        [[-1.0455e+00, -9.6119e-01, -1.6556e-01,  ..., -1.0303e+00,\n",
       "          -1.1615e+00, -8.5193e-01],\n",
       "         [-2.8459e-01,  1.3672e-01, -4.3685e-01,  ..., -1.0596e+00,\n",
       "          -3.6348e-01,  7.1783e-01],\n",
       "         [-4.3979e-01,  3.1879e-01, -9.2815e-01,  ..., -1.4902e+00,\n",
       "          -6.0167e-01,  4.6884e-01],\n",
       "         ...,\n",
       "         [-1.3298e+00, -1.0826e+00,  8.9230e-01,  ..., -3.0971e-01,\n",
       "          -2.1085e-01, -2.6704e-01],\n",
       "         [ 1.3228e-02,  7.7057e-01, -5.3141e-01,  ..., -9.7041e-01,\n",
       "          -8.0907e-01, -4.8343e-01],\n",
       "         [-9.1154e-01,  8.7167e-02, -7.1329e-01,  ..., -7.9729e-01,\n",
       "          -1.1712e+00,  6.9481e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.0224e-01,  2.0245e-01,  3.9755e-01,  ..., -6.0160e-01,\n",
       "          -2.0485e+00, -1.1385e+00],\n",
       "         [ 3.2696e-01, -5.6573e-01, -7.5497e-02,  ..., -1.0369e+00,\n",
       "          -1.2420e+00, -8.7940e-01],\n",
       "         [-5.0304e-01,  4.5067e-01,  5.7603e-01,  ...,  2.0233e-01,\n",
       "          -5.8792e-01, -2.3018e-01],\n",
       "         ...,\n",
       "         [-1.7542e+00,  1.1714e-01,  3.8477e-04,  ..., -4.7988e-01,\n",
       "          -5.5316e-01,  5.4055e-01],\n",
       "         [-2.4738e-01, -2.5594e-01, -1.6545e-01,  ...,  5.2236e-01,\n",
       "          -5.2841e-01,  8.3290e-01],\n",
       "         [-1.6438e+00, -8.4994e-01,  2.4384e-01,  ..., -2.5692e+00,\n",
       "          -1.2204e-01,  4.6653e-01]],\n",
       "\n",
       "        [[-7.4610e-01, -1.1556e+00, -5.1005e-01,  ..., -2.8593e-01,\n",
       "          -3.0638e-01,  1.4797e-01],\n",
       "         [-4.2616e-01, -1.4636e+00, -6.9284e-01,  ...,  9.1623e-01,\n",
       "          -1.7079e+00,  2.9688e-01],\n",
       "         [-1.1389e+00,  7.4014e-01, -5.5843e-01,  ...,  2.7437e-02,\n",
       "           2.9796e-01,  7.2140e-01],\n",
       "         ...,\n",
       "         [-6.8649e-01,  3.7593e-01,  1.1418e+00,  ..., -1.3361e+00,\n",
       "          -1.0669e+00, -3.2603e-01],\n",
       "         [-8.1310e-01, -3.8430e-01, -1.3924e+00,  ..., -1.3097e+00,\n",
       "          -2.1249e-01,  6.9025e-03],\n",
       "         [-6.6168e-01, -1.2448e-01,  5.8890e-01,  ..., -1.3211e+00,\n",
       "          -1.2963e-01,  9.0089e-01]],\n",
       "\n",
       "        [[-1.9446e+00,  4.8378e-01,  2.3132e-01,  ..., -3.9238e-01,\n",
       "          -5.5967e-01, -4.5665e-01],\n",
       "         [-6.5586e-01, -1.3169e+00, -3.3304e-01,  ..., -8.5248e-01,\n",
       "          -1.5199e-01,  8.5693e-01],\n",
       "         [ 1.8405e+00, -2.1855e-01, -1.2499e+00,  ...,  4.9532e-02,\n",
       "          -8.3157e-01, -4.8152e-01],\n",
       "         ...,\n",
       "         [-3.2245e-01,  1.9059e-01, -5.2654e-01,  ..., -8.4634e-01,\n",
       "          -5.2672e-01, -5.0721e-01],\n",
       "         [-1.7885e+00, -1.3090e+00, -7.4615e-02,  ..., -1.3887e+00,\n",
       "          -2.1072e+00,  8.1723e-01],\n",
       "         [-3.0564e-01,  1.8610e-01, -5.6554e-01,  ..., -1.0022e+00,\n",
       "          -1.6498e+00, -1.2565e+00]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_lbl0 = mod_enc.layers[0]\n",
    "\n",
    "script_lbl0 = torch.jit.trace_module(mod_lbl0, {'forward': (src,)},check_trace=False)\n",
    "print(script_lbl0.code)\n",
    "script_lbl0(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db1baa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== USING SCRIPT =====\n",
      "def multi_head_attention_forward(query: Tensor,\n",
      "    key: Tensor,\n",
      "    value: Tensor,\n",
      "    embed_dim_to_check: int,\n",
      "    num_heads: int,\n",
      "    in_proj_weight: Tensor,\n",
      "    in_proj_bias: Optional[Tensor],\n",
      "    bias_k: Optional[Tensor],\n",
      "    bias_v: Optional[Tensor],\n",
      "    add_zero_attn: bool,\n",
      "    dropout_p: float,\n",
      "    out_proj_weight: Tensor,\n",
      "    out_proj_bias: Optional[Tensor],\n",
      "    training: bool=True,\n",
      "    key_padding_mask: Optional[Tensor]=None,\n",
      "    need_weights: bool=True,\n",
      "    attn_mask: Optional[Tensor]=None,\n",
      "    use_separate_proj_weight: bool=False,\n",
      "    q_proj_weight: Optional[Tensor]=None,\n",
      "    k_proj_weight: Optional[Tensor]=None,\n",
      "    v_proj_weight: Optional[Tensor]=None,\n",
      "    static_k: Optional[Tensor]=None,\n",
      "    static_v: Optional[Tensor]=None,\n",
      "    average_attn_weights: bool=True) -> Tuple[Tensor, Optional[Tensor]]:\n",
      "  _0 = __torch__.torch.nn.functional._mha_shape_check\n",
      "  _1 = \"was expecting embedding dimension of {}, but got {}\"\n",
      "  _2 = \"embed_dim {} not divisible by num_heads {}\"\n",
      "  _3 = \"key\\'s sequence and batch dims {} do not match value\\'s {}\"\n",
      "  _4 = \"key shape {} does not match value shape {}\"\n",
      "  _5 = __torch__.torch.nn.functional._in_projection_packed\n",
      "  _6 = \"AssertionError: use_separate_proj_weight is True but q_proj_weight is None\"\n",
      "  _7 = \"AssertionError: use_separate_proj_weight is True but k_proj_weight is None\"\n",
      "  _8 = \"AssertionError: use_separate_proj_weight is True but v_proj_weight is None\"\n",
      "  _9 = __torch__.torch.nn.functional._in_projection\n",
      "  _10 = \"Byte tensor for attn_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\"\n",
      "  _11 = \"Only float, byte, and bool types are supported for attn_mask, not {}\"\n",
      "  _12 = \"The shape of the 2D attn_mask is {}, but should be {}.\"\n",
      "  _13 = \"The shape of the 3D attn_mask is {}, but should be {}.\"\n",
      "  _14 = \"attn_mask\\'s dimension {} is not supported\"\n",
      "  _15 = \"Byte tensor for key_padding_mask in nn.MultiheadAttention is deprecated. Use bool tensor instead.\"\n",
      "  _16 = \"AssertionError: bias cannot be added to static key.\"\n",
      "  _17 = \"AssertionError: bias cannot be added to static value.\"\n",
      "  _18 = \"expecting static_k.size(0) of {}, but got {}\"\n",
      "  _19 = \"expecting static_k.size(2) of {}, but got {}\"\n",
      "  _20 = \"expecting static_v.size(0) of {}, but got {}\"\n",
      "  _21 = \"expecting static_v.size(2) of {}, but got {}\"\n",
      "  _22 = \"expecting key_padding_mask shape of {}, but got {}\"\n",
      "  _23 = __torch__.torch.nn.functional._scaled_dot_product_attention\n",
      "  _24 = uninitialized(Optional[Tensor])\n",
      "  _25 = uninitialized(Optional[Tensor])\n",
      "  _26 = uninitialized(Tensor)\n",
      "  is_batched = _0(query, key, value, key_padding_mask, attn_mask, num_heads, )\n",
      "  if torch.__not__(is_batched):\n",
      "    query1 = torch.unsqueeze(query, 1)\n",
      "    key1 = torch.unsqueeze(key, 1)\n",
      "    value1 = torch.unsqueeze(value, 1)\n",
      "    _27 = torch.__isnot__(key_padding_mask, None)\n",
      "    if _27:\n",
      "      key_padding_mask2 = unchecked_cast(Tensor, key_padding_mask)\n",
      "      key_padding_mask3 = torch.unsqueeze(key_padding_mask2, 0)\n",
      "      key_padding_mask1 : Optional[Tensor] = key_padding_mask3\n",
      "    else:\n",
      "      key_padding_mask1 = key_padding_mask\n",
      "    query0, key0, value0, key_padding_mask0 = query1, key1, value1, key_padding_mask1\n",
      "  else:\n",
      "    query0, key0, value0, key_padding_mask0 = query, key, value, key_padding_mask\n",
      "  tgt_len, bsz, embed_dim, = torch.size(query0)\n",
      "  src_len, _28, _29, = torch.size(key0)\n",
      "  _30 = torch.eq(embed_dim, embed_dim_to_check)\n",
      "  if _30:\n",
      "    pass\n",
      "  else:\n",
      "    _31 = torch.format(_1, embed_dim_to_check, embed_dim)\n",
      "    ops.prim.RaiseException(torch.add(\"AssertionError: \", _31))\n",
      "  embed_dim0 = unchecked_cast(int, embed_dim)\n",
      "  head_dim = torch.floordiv(embed_dim0, num_heads)\n",
      "  _32 = torch.eq(torch.mul(head_dim, num_heads), embed_dim0)\n",
      "  if _32:\n",
      "    pass\n",
      "  else:\n",
      "    _33 = torch.format(_2, embed_dim0, num_heads)\n",
      "    ops.prim.RaiseException(torch.add(\"AssertionError: \", _33))\n",
      "  if use_separate_proj_weight:\n",
      "    _34 = torch.slice(torch.size(key0), None, 2)\n",
      "    _35 = torch.slice(torch.size(value0), None, 2)\n",
      "    if torch.eq(_34, _35):\n",
      "      pass\n",
      "    else:\n",
      "      _36 = torch.slice(torch.size(key0), None, 2)\n",
      "      _37 = torch.slice(torch.size(value0), None, 2)\n",
      "      _38 = torch.add(\"AssertionError: \", torch.format(_3, _36, _37))\n",
      "      ops.prim.RaiseException(_38)\n",
      "  else:\n",
      "    _39 = torch.eq(torch.size(key0), torch.size(value0))\n",
      "    if _39:\n",
      "      pass\n",
      "    else:\n",
      "      _40 = torch.format(_4, torch.size(key0), torch.size(value0))\n",
      "      _41 = torch.add(\"AssertionError: \", _40)\n",
      "      ops.prim.RaiseException(_41)\n",
      "  _42 = torch.__not__(use_separate_proj_weight)\n",
      "  if _42:\n",
      "    _43 = _5(query0, key0, value0, in_proj_weight, in_proj_bias, )\n",
      "    q0, k0, v0, = _43\n",
      "    k, v, q = k0, v0, q0\n",
      "  else:\n",
      "    _44 = torch.__isnot__(q_proj_weight, None)\n",
      "    if _44:\n",
      "      q_proj_weight1 = unchecked_cast(Tensor, q_proj_weight)\n",
      "      q_proj_weight0 = q_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_6)\n",
      "      q_proj_weight0 = _26\n",
      "    _45 = torch.__isnot__(k_proj_weight, None)\n",
      "    if _45:\n",
      "      k_proj_weight1 = unchecked_cast(Tensor, k_proj_weight)\n",
      "      k_proj_weight0 = k_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_7)\n",
      "      k_proj_weight0 = _26\n",
      "    _46 = torch.__isnot__(v_proj_weight, None)\n",
      "    if _46:\n",
      "      v_proj_weight1 = unchecked_cast(Tensor, v_proj_weight)\n",
      "      v_proj_weight0 = v_proj_weight1\n",
      "    else:\n",
      "      ops.prim.RaiseException(_8)\n",
      "      v_proj_weight0 = _26\n",
      "    if torch.__is__(in_proj_bias, None):\n",
      "      b_q, b_k, b_v = None, None, None\n",
      "    else:\n",
      "      in_proj_bias0 = unchecked_cast(Tensor, in_proj_bias)\n",
      "      b_q0, b_k0, b_v0, = torch.chunk(in_proj_bias0, 3)\n",
      "      b_q, b_k, b_v = b_q0, b_k0, b_v0\n",
      "    _47 = _9(query0, key0, value0, q_proj_weight0, k_proj_weight0, v_proj_weight0, b_q, b_k, b_v, )\n",
      "    q1, k1, v1, = _47\n",
      "    k, v, q = k1, v1, q1\n",
      "  if torch.__isnot__(attn_mask, None):\n",
      "    attn_mask1 = unchecked_cast(Tensor, attn_mask)\n",
      "    _48 = torch.eq(ops.prim.dtype(attn_mask1), 0)\n",
      "    if _48:\n",
      "      torch.warn(_10)\n",
      "      attn_mask2 = torch.to(attn_mask1, 11)\n",
      "    else:\n",
      "      _49 = torch.is_floating_point(attn_mask1)\n",
      "      if _49:\n",
      "        _50 = True\n",
      "      else:\n",
      "        _51 = torch.eq(ops.prim.dtype(attn_mask1), 11)\n",
      "        _50 = _51\n",
      "      if _50:\n",
      "        pass\n",
      "      else:\n",
      "        _52 = torch.format(_11, ops.prim.dtype(attn_mask1))\n",
      "        _53 = torch.add(\"AssertionError: \", _52)\n",
      "        ops.prim.RaiseException(_53)\n",
      "      attn_mask2 = attn_mask1\n",
      "    if torch.eq(torch.dim(attn_mask2), 2):\n",
      "      correct_2d_size = (tgt_len, src_len)\n",
      "      _54 = torch.ne(torch.size(attn_mask2), [tgt_len, src_len])\n",
      "      if _54:\n",
      "        _55 = torch.format(_12, torch.size(attn_mask2), correct_2d_size)\n",
      "        ops.prim.RaiseException(_55)\n",
      "      else:\n",
      "        pass\n",
      "      attn_mask3 = torch.unsqueeze(attn_mask2, 0)\n",
      "    else:\n",
      "      _56 = torch.eq(torch.dim(attn_mask2), 3)\n",
      "      if _56:\n",
      "        _57 = torch.mul(bsz, num_heads)\n",
      "        correct_3d_size = (_57, tgt_len, src_len)\n",
      "        _58 = torch.ne(torch.size(attn_mask2), [_57, tgt_len, src_len])\n",
      "        if _58:\n",
      "          _59 = torch.format(_13, torch.size(attn_mask2), correct_3d_size)\n",
      "          ops.prim.RaiseException(_59)\n",
      "        else:\n",
      "          pass\n",
      "      else:\n",
      "        _60 = torch.format(_14, torch.dim(attn_mask2))\n",
      "        ops.prim.RaiseException(_60)\n",
      "      attn_mask3 = attn_mask2\n",
      "    attn_mask0 : Optional[Tensor] = attn_mask3\n",
      "  else:\n",
      "    attn_mask0 = attn_mask\n",
      "  _61 = torch.__isnot__(key_padding_mask0, None)\n",
      "  if _61:\n",
      "    key_padding_mask5 = unchecked_cast(Tensor, key_padding_mask0)\n",
      "    _63 = torch.eq(ops.prim.dtype(key_padding_mask5), 0)\n",
      "    _62, key_padding_mask4 = _63, key_padding_mask5\n",
      "  else:\n",
      "    _62, key_padding_mask4 = False, key_padding_mask0\n",
      "  if _62:\n",
      "    key_padding_mask7 = unchecked_cast(Tensor, key_padding_mask4)\n",
      "    torch.warn(_15)\n",
      "    key_padding_mask6 : Optional[Tensor] = torch.to(key_padding_mask7, 11)\n",
      "  else:\n",
      "    key_padding_mask6 = key_padding_mask4\n",
      "  if torch.__isnot__(bias_k, None):\n",
      "    bias_k1 = unchecked_cast(Tensor, bias_k)\n",
      "    _64, bias_k0 = torch.__isnot__(bias_v, None), bias_k1\n",
      "  else:\n",
      "    _64, bias_k0 = False, bias_k\n",
      "  if _64:\n",
      "    bias_k2 = unchecked_cast(Tensor, bias_k0)\n",
      "    bias_v0 = unchecked_cast(Tensor, bias_v)\n",
      "    if torch.__is__(static_k, None):\n",
      "      static_k1 : Optional[Tensor] = static_k\n",
      "    else:\n",
      "      ops.prim.RaiseException(_16)\n",
      "      static_k1 = _25\n",
      "    if torch.__is__(static_v, None):\n",
      "      static_v1 : Optional[Tensor] = static_v\n",
      "    else:\n",
      "      ops.prim.RaiseException(_17)\n",
      "      static_v1 = _24\n",
      "    _65 = [k, torch.repeat(bias_k2, [1, bsz, 1])]\n",
      "    k3 = torch.cat(_65)\n",
      "    _66 = [v, torch.repeat(bias_v0, [1, bsz, 1])]\n",
      "    v3 = torch.cat(_66)\n",
      "    if torch.__isnot__(attn_mask0, None):\n",
      "      attn_mask6 = unchecked_cast(Tensor, attn_mask0)\n",
      "      attn_mask7 = __torch__.torch.nn.functional._pad(attn_mask6, [0, 1], \"constant\", 0., )\n",
      "      attn_mask5 : Optional[Tensor] = attn_mask7\n",
      "    else:\n",
      "      attn_mask5 = attn_mask0\n",
      "    _67 = torch.__isnot__(key_padding_mask6, None)\n",
      "    if _67:\n",
      "      key_padding_mask10 = unchecked_cast(Tensor, key_padding_mask6)\n",
      "      key_padding_mask11 = __torch__.torch.nn.functional._pad(key_padding_mask10, [0, 1], \"constant\", 0., )\n",
      "      key_padding_mask9 : Optional[Tensor] = key_padding_mask11\n",
      "    else:\n",
      "      key_padding_mask9 = key_padding_mask6\n",
      "    static_k0, k2, static_v0, v2, attn_mask4, key_padding_mask8 = static_k1, k3, static_v1, v3, attn_mask5, key_padding_mask9\n",
      "  else:\n",
      "    if torch.__is__(bias_k0, None):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    if torch.__is__(bias_v, None):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    static_k0, k2, static_v0, v2, attn_mask4, key_padding_mask8 = static_k, k, static_v, v, attn_mask0, key_padding_mask6\n",
      "  _68 = torch.contiguous(q)\n",
      "  _69 = [tgt_len, torch.mul(bsz, num_heads), head_dim]\n",
      "  q2 = torch.transpose(torch.view(_68, _69), 0, 1)\n",
      "  if torch.__is__(static_k0, None):\n",
      "    _70 = torch.contiguous(k2)\n",
      "    _71 = [(torch.size(k2))[0], torch.mul(bsz, num_heads), head_dim]\n",
      "    k5 = torch.transpose(torch.view(_70, _71), 0, 1)\n",
      "    k4 = k5\n",
      "  else:\n",
      "    static_k2 = unchecked_cast(Tensor, static_k0)\n",
      "    _72 = torch.eq(torch.size(static_k2, 0), torch.mul(bsz, num_heads))\n",
      "    if _72:\n",
      "      pass\n",
      "    else:\n",
      "      _73 = torch.format(_18, torch.mul(bsz, num_heads), torch.size(static_k2, 0))\n",
      "      _74 = torch.add(\"AssertionError: \", _73)\n",
      "      ops.prim.RaiseException(_74)\n",
      "    _75 = torch.eq(torch.size(static_k2, 2), head_dim)\n",
      "    if _75:\n",
      "      pass\n",
      "    else:\n",
      "      _76 = torch.format(_19, head_dim, torch.size(static_k2, 2))\n",
      "      _77 = torch.add(\"AssertionError: \", _76)\n",
      "      ops.prim.RaiseException(_77)\n",
      "    k4 = static_k2\n",
      "  if torch.__is__(static_v0, None):\n",
      "    _78 = torch.contiguous(v2)\n",
      "    _79 = [(torch.size(v2))[0], torch.mul(bsz, num_heads), head_dim]\n",
      "    v5 = torch.transpose(torch.view(_78, _79), 0, 1)\n",
      "    v4 = v5\n",
      "  else:\n",
      "    static_v2 = unchecked_cast(Tensor, static_v0)\n",
      "    _80 = torch.eq(torch.size(static_v2, 0), torch.mul(bsz, num_heads))\n",
      "    if _80:\n",
      "      pass\n",
      "    else:\n",
      "      _81 = torch.format(_20, torch.mul(bsz, num_heads), torch.size(static_v2, 0))\n",
      "      _82 = torch.add(\"AssertionError: \", _81)\n",
      "      ops.prim.RaiseException(_82)\n",
      "    _83 = torch.eq(torch.size(static_v2, 2), head_dim)\n",
      "    if _83:\n",
      "      pass\n",
      "    else:\n",
      "      _84 = torch.format(_21, head_dim, torch.size(static_v2, 2))\n",
      "      _85 = torch.add(\"AssertionError: \", _84)\n",
      "      ops.prim.RaiseException(_85)\n",
      "    v4 = static_v2\n",
      "  if add_zero_attn:\n",
      "    _86 = torch.mul(bsz, num_heads)\n",
      "    _87 = ops.prim.dtype(k4)\n",
      "    _88 = ops.prim.device(k4)\n",
      "    _89 = torch.zeros([_86, 1, head_dim], dtype=_87, layout=None, device=_88)\n",
      "    k7 = torch.cat([k4, _89], 1)\n",
      "    _90 = ops.prim.dtype(v4)\n",
      "    _91 = ops.prim.device(v4)\n",
      "    _92 = torch.zeros([_86, 1, head_dim], dtype=_90, layout=None, device=_91)\n",
      "    v7 = torch.cat([v4, _92], 1)\n",
      "    if torch.__isnot__(attn_mask4, None):\n",
      "      attn_mask10 = unchecked_cast(Tensor, attn_mask4)\n",
      "      attn_mask11 = __torch__.torch.nn.functional._pad(attn_mask10, [0, 1], \"constant\", 0., )\n",
      "      attn_mask9 : Optional[Tensor] = attn_mask11\n",
      "    else:\n",
      "      attn_mask9 = attn_mask4\n",
      "    _93 = torch.__isnot__(key_padding_mask8, None)\n",
      "    if _93:\n",
      "      key_padding_mask14 = unchecked_cast(Tensor, key_padding_mask8)\n",
      "      key_padding_mask15 = __torch__.torch.nn.functional._pad(key_padding_mask14, [0, 1], \"constant\", 0., )\n",
      "      key_padding_mask13 : Optional[Tensor] = key_padding_mask15\n",
      "    else:\n",
      "      key_padding_mask13 = key_padding_mask8\n",
      "    k6, key_padding_mask12, attn_mask8, v6 = k7, key_padding_mask13, attn_mask9, v7\n",
      "  else:\n",
      "    k6, key_padding_mask12, attn_mask8, v6 = k4, key_padding_mask8, attn_mask4, v4\n",
      "  src_len0 = torch.size(k6, 1)\n",
      "  _94 = torch.__isnot__(key_padding_mask12, None)\n",
      "  if _94:\n",
      "    key_padding_mask16 = unchecked_cast(Tensor, key_padding_mask12)\n",
      "    _95 = torch.eq(torch.size(key_padding_mask16), [bsz, src_len0])\n",
      "    if _95:\n",
      "      pass\n",
      "    else:\n",
      "      _96 = torch.format(_22, (bsz, src_len0), torch.size(key_padding_mask16))\n",
      "      _97 = torch.add(\"AssertionError: \", _96)\n",
      "      ops.prim.RaiseException(_97)\n",
      "    _98 = torch.view(key_padding_mask16, [bsz, 1, 1, src_len0])\n",
      "    _99 = torch.expand(_98, [-1, num_heads, -1, -1])\n",
      "    _100 = [torch.mul(bsz, num_heads), 1, src_len0]\n",
      "    key_padding_mask17 = torch.reshape(_99, _100)\n",
      "    if torch.__is__(attn_mask8, None):\n",
      "      attn_mask13 = key_padding_mask17\n",
      "    else:\n",
      "      attn_mask14 = unchecked_cast(Tensor, attn_mask8)\n",
      "      _101 = torch.eq(ops.prim.dtype(attn_mask14), 11)\n",
      "      if _101:\n",
      "        attn_mask16 = torch.logical_or(attn_mask14, key_padding_mask17)\n",
      "        attn_mask15 = attn_mask16\n",
      "      else:\n",
      "        attn_mask17 = torch.masked_fill(attn_mask14, key_padding_mask17, -inf)\n",
      "        attn_mask15 = attn_mask17\n",
      "      attn_mask13 = attn_mask15\n",
      "    attn_mask12 : Optional[Tensor] = attn_mask13\n",
      "  else:\n",
      "    attn_mask12 = attn_mask8\n",
      "  if torch.__isnot__(attn_mask12, None):\n",
      "    attn_mask19 = unchecked_cast(Tensor, attn_mask12)\n",
      "    _103 = torch.eq(ops.prim.dtype(attn_mask19), 11)\n",
      "    _102, attn_mask18 = _103, attn_mask19\n",
      "  else:\n",
      "    _102, attn_mask18 = False, attn_mask12\n",
      "  if _102:\n",
      "    attn_mask21 = unchecked_cast(Tensor, attn_mask18)\n",
      "    new_attn_mask = torch.zeros_like(attn_mask21, dtype=ops.prim.dtype(q2))\n",
      "    _104 = torch.masked_fill_(new_attn_mask, attn_mask21, -inf)\n",
      "    attn_mask20 : Optional[Tensor] = new_attn_mask\n",
      "  else:\n",
      "    attn_mask20 = attn_mask18\n",
      "  if torch.__not__(training):\n",
      "    dropout_p0 = 0.\n",
      "  else:\n",
      "    dropout_p0 = dropout_p\n",
      "  _105 = _23(q2, k6, v6, attn_mask20, dropout_p0, )\n",
      "  attn_output, attn_output_weights, = _105\n",
      "  _106 = torch.contiguous(torch.transpose(attn_output, 0, 1))\n",
      "  attn_output0 = torch.view(_106, [tgt_len, bsz, embed_dim0])\n",
      "  attn_output1 = torch.linear(attn_output0, out_proj_weight, out_proj_bias)\n",
      "  if need_weights:\n",
      "    attn_output_weights0 = torch.view(attn_output_weights, [bsz, num_heads, tgt_len, src_len0])\n",
      "    if average_attn_weights:\n",
      "      _108 = torch.sum(attn_output_weights0, [1])\n",
      "      attn_output_weights1 = torch.div(_108, num_heads)\n",
      "    else:\n",
      "      attn_output_weights1 = attn_output_weights0\n",
      "    if torch.__not__(is_batched):\n",
      "      attn_output3 = torch.squeeze(attn_output1, 1)\n",
      "      attn_output_weights3 = torch.squeeze(attn_output_weights1, 0)\n",
      "      attn_output2, attn_output_weights2 = attn_output3, attn_output_weights3\n",
      "    else:\n",
      "      attn_output2, attn_output_weights2 = attn_output1, attn_output_weights1\n",
      "    _109 = (attn_output2, attn_output_weights2)\n",
      "    _107 = _109\n",
      "  else:\n",
      "    if torch.__not__(is_batched):\n",
      "      attn_output4 = torch.squeeze(attn_output1, 1)\n",
      "    else:\n",
      "      attn_output4 = attn_output1\n",
      "    _107 = (attn_output4, None)\n",
      "  return _107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theotime/.local/lib/python3.10/site-packages/torch/jit/_script.py:1259: UserWarning: Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType to enable Profile-Directed Typing in TorchScript. Refer to https://github.com/Instagram/MonkeyType/blob/master/README.rst to install MonkeyType. \n",
      "  warnings.warn(\"Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType \"\n"
     ]
    }
   ],
   "source": [
    "script_nn = torch.jit.script(torch.nn.functional.multi_head_attention_forward,example_inputs=[(src,src,src, 512, 16,\n",
    "       in_proj_weight, in_proj_bias, None, None, False, 0.1, out_proj_weight, \n",
    "        out_proj_bias, True, None, True, \n",
    "        None, False, None, None, \n",
    "        None, None, None)])\n",
    "print(\"===== USING SCRIPT =====\")\n",
    "print(script_nn.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df6b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.fx as fx\n",
    "\n",
    "mod_tf = nn.Transformer(nhead=16, num_encoder_layers=1)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((10, 32, 512))\n",
    "\n",
    "jit_tf = torch.jit.trace_module(mod_tf.encoder.layers[0],{\"forward\":(src)},check_trace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8278118c-9234-4005-8113-09f70ad0d600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.torch.nn.modules.transformer.___torch_mangle_145.TransformerEncoderLayer,\n",
      "      %src : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=0, device=cpu)):\n",
      "  %norm2 : __torch__.torch.nn.modules.normalization.___torch_mangle_142.LayerNorm = prim::GetAttr[name=\"norm2\"](%self.1)\n",
      "  %dropout2 : __torch__.torch.nn.modules.dropout.___torch_mangle_144.Dropout = prim::GetAttr[name=\"dropout2\"](%self.1)\n",
      "  %linear2 : __torch__.torch.nn.modules.linear.___torch_mangle_140.Linear = prim::GetAttr[name=\"linear2\"](%self.1)\n",
      "  %dropout : __torch__.torch.nn.modules.dropout.___torch_mangle_139.Dropout = prim::GetAttr[name=\"dropout\"](%self.1)\n",
      "  %linear1 : __torch__.torch.nn.modules.linear.___torch_mangle_138.Linear = prim::GetAttr[name=\"linear1\"](%self.1)\n",
      "  %norm1 : __torch__.torch.nn.modules.normalization.___torch_mangle_141.LayerNorm = prim::GetAttr[name=\"norm1\"](%self.1)\n",
      "  %dropout1 : __torch__.torch.nn.modules.dropout.___torch_mangle_143.Dropout = prim::GetAttr[name=\"dropout1\"](%self.1)\n",
      "  %self_attn : __torch__.torch.nn.modules.activation.___torch_mangle_137.MultiheadAttention = prim::GetAttr[name=\"self_attn\"](%self.1)\n",
      "  %23 : bool = prim::Constant[value=1](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %24 : float = prim::Constant[value=0.10000000000000001](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %25 : NoneType = prim::Constant(), scope: __module.self_attn\n",
      "  %26 : int = prim::Constant[value=-2](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5032:0\n",
      "  %27 : Double(requires_grad=0, device=cpu) = prim::Constant[value={5.65685}](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5031:0\n",
      "  %28 : int = prim::Constant[value=-1](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:4926:0\n",
      "  %29 : int = prim::Constant[value=3](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:4926:0\n",
      "  %30 : str = prim::Constant[value=\"trunc\"](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5217:0\n",
      "  %31 : Long(requires_grad=0, device=cpu) = prim::Constant[value={16}](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5217:0\n",
      "  %32 : int = prim::Constant[value=2](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %33 : int = prim::Constant[value=1](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %34 : int = prim::Constant[value=0](), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %out_proj : __torch__.torch.nn.modules.linear.___torch_mangle_136.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn)\n",
      "  %bias.5 : Tensor = prim::GetAttr[name=\"bias\"](%out_proj)\n",
      "  %out_proj.1 : __torch__.torch.nn.modules.linear.___torch_mangle_136.NonDynamicallyQuantizableLinear = prim::GetAttr[name=\"out_proj\"](%self_attn)\n",
      "  %weight.5 : Tensor = prim::GetAttr[name=\"weight\"](%out_proj.1)\n",
      "  %in_proj_bias : Tensor = prim::GetAttr[name=\"in_proj_bias\"](%self_attn)\n",
      "  %in_proj_weight : Tensor = prim::GetAttr[name=\"in_proj_weight\"](%self_attn)\n",
      "  %41 : int = aten::size(%src, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %42 : int = aten::size(%src, %33), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %bsz : Long(device=cpu) = prim::NumToTensor(%42), scope: __module.self_attn\n",
      "  %44 : int = aten::size(%src, %32), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5207:0\n",
      "  %embed_dim : Long(device=cpu) = prim::NumToTensor(%44), scope: __module.self_attn\n",
      "  %head_dim : Long(requires_grad=0, device=cpu) = aten::div(%embed_dim, %31, %30), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5217:0\n",
      "  %47 : int = aten::Int(%head_dim), scope: __module.self_attn\n",
      "  %48 : int = aten::Int(%head_dim), scope: __module.self_attn\n",
      "  %49 : int = aten::Int(%head_dim), scope: __module.self_attn\n",
      "  %50 : Float(10, 32, 1536, strides=[49152, 1536, 1], requires_grad=1, device=cpu) = aten::linear(%src, %in_proj_weight, %in_proj_bias), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:4925:0\n",
      "  %51 : Tensor[] = aten::chunk(%50, %29, %28), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:4926:0\n",
      "  %q.1 : Float(10, 32, 512, strides=[49152, 1536, 1], requires_grad=1, device=cpu), %k.1 : Float(10, 32, 512, strides=[49152, 1536, 1], requires_grad=1, device=cpu), %v.1 : Float(10, 32, 512, strides=[49152, 1536, 1], requires_grad=1, device=cpu) = prim::ListUnpack(%51), scope: __module.self_attn\n",
      "  %55 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::contiguous(%q.1, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5253:0\n",
      "  %56 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %31), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %57 : int = aten::Int(%56), scope: __module.self_attn\n",
      "  %58 : int[] = prim::ListConstruct(%41, %57, %49), scope: __module.self_attn\n",
      "  %59 : Float(10, 512, 32, strides=[16384, 32, 1], requires_grad=1, device=cpu) = aten::view(%55, %58), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %q.3 : Float(512, 10, 32, strides=[32, 16384, 1], requires_grad=1, device=cpu) = aten::transpose(%59, %34, %33), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %61 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::contiguous(%k.1, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %62 : int = aten::size(%k.1, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %63 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %31), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %64 : int = aten::Int(%63), scope: __module.self_attn\n",
      "  %65 : int[] = prim::ListConstruct(%62, %64, %48), scope: __module.self_attn\n",
      "  %66 : Float(10, 512, 32, strides=[16384, 32, 1], requires_grad=1, device=cpu) = aten::view(%61, %65), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5254:0\n",
      "  %k : Float(512, 10, 32, strides=[32, 16384, 1], requires_grad=1, device=cpu) = aten::transpose(%66, %34, %33), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5257:0\n",
      "  %68 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::contiguous(%v.1, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5262:0\n",
      "  %69 : int = aten::size(%v.1, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5262:0\n",
      "  %70 : Long(requires_grad=0, device=cpu) = aten::mul(%bsz, %31), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5262:0\n",
      "  %71 : int = aten::Int(%70), scope: __module.self_attn\n",
      "  %72 : int[] = prim::ListConstruct(%69, %71, %47), scope: __module.self_attn\n",
      "  %73 : Float(10, 512, 32, strides=[16384, 32, 1], requires_grad=1, device=cpu) = aten::view(%68, %72), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5262:0\n",
      "  %v : Float(512, 10, 32, strides=[32, 16384, 1], requires_grad=1, device=cpu) = aten::transpose(%73, %34, %33), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5262:0\n",
      "  %q : Float(512, 10, 32, strides=[32, 16384, 1], requires_grad=1, device=cpu) = aten::div(%q.3, %27), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5031:0\n",
      "  %76 : Float(512, 32, 10, strides=[32, 1, 16384], requires_grad=1, device=cpu) = aten::transpose(%k, %26, %28), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5032:0\n",
      "  %input.1 : Float(512, 10, 10, strides=[100, 10, 1], requires_grad=1, device=cpu) = aten::bmm(%q, %76), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5032:0\n",
      "  %input.3 : Float(512, 10, 10, strides=[100, 10, 1], requires_grad=1, device=cpu) = aten::softmax(%input.1, %28, %25), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1815:0\n",
      "  %attn : Float(512, 10, 10, strides=[100, 10, 1], requires_grad=1, device=cpu) = aten::dropout(%input.3, %24, %23), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %attn_output.1 : Float(512, 10, 32, strides=[320, 32, 1], requires_grad=1, device=cpu) = aten::bmm(%attn, %v), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5035:0\n",
      "  %81 : Float(10, 512, 32, strides=[32, 320, 1], requires_grad=1, device=cpu) = aten::transpose(%attn_output.1, %34, %33), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5284:0\n",
      "  %82 : Float(10, 512, 32, strides=[16384, 32, 1], requires_grad=1, device=cpu) = aten::contiguous(%81, %34), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5284:0\n",
      "  %83 : int[] = prim::ListConstruct(%41, %42, %44), scope: __module.self_attn\n",
      "  %attn_output : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::view(%82, %83), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5284:0\n",
      "  %input.5 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::linear(%attn_output, %weight.5, %bias.5), scope: __module.self_attn # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:5285:0\n",
      "  %86 : bool = prim::Constant[value=1](), scope: __module.dropout1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %87 : float = prim::Constant[value=0.10000000000000001](), scope: __module.dropout1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %88 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::dropout(%input.5, %87, %86), scope: __module.dropout1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %12 : int = prim::Constant[value=1]() # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:342:0\n",
      "  %input.7 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::add(%src, %88, %12) # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:342:0\n",
      "  %89 : bool = prim::Constant[value=1](), scope: __module.norm1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %90 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.norm1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %91 : int = prim::Constant[value=512](), scope: __module.norm1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %bias.7 : Tensor = prim::GetAttr[name=\"bias\"](%norm1)\n",
      "  %weight.7 : Tensor = prim::GetAttr[name=\"weight\"](%norm1)\n",
      "  %94 : int[] = prim::ListConstruct(%91), scope: __module.norm1\n",
      "  %input.9 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::layer_norm(%input.7, %94, %weight.7, %bias.7, %90, %89), scope: __module.norm1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %bias.9 : Tensor = prim::GetAttr[name=\"bias\"](%linear1)\n",
      "  %weight.9 : Tensor = prim::GetAttr[name=\"weight\"](%linear1)\n",
      "  %input.11 : Float(10, 32, 2048, strides=[65536, 2048, 1], requires_grad=1, device=cpu) = aten::linear(%input.9, %weight.9, %bias.9), scope: __module.linear1 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %input.13 : Float(10, 32, 2048, strides=[65536, 2048, 1], requires_grad=1, device=cpu) = aten::relu(%input.11) # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1438:0\n",
      "  %99 : bool = prim::Constant[value=1](), scope: __module.dropout # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %100 : float = prim::Constant[value=0.10000000000000001](), scope: __module.dropout # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %input.15 : Float(10, 32, 2048, strides=[65536, 2048, 1], requires_grad=1, device=cpu) = aten::dropout(%input.13, %100, %99), scope: __module.dropout # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %bias.11 : Tensor = prim::GetAttr[name=\"bias\"](%linear2)\n",
      "  %weight.11 : Tensor = prim::GetAttr[name=\"weight\"](%linear2)\n",
      "  %input.17 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::linear(%input.15, %weight.11, %bias.11), scope: __module.linear2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:103:0\n",
      "  %105 : bool = prim::Constant[value=1](), scope: __module.dropout2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %106 : float = prim::Constant[value=0.10000000000000001](), scope: __module.dropout2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %107 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::dropout(%input.17, %106, %105), scope: __module.dropout2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:1277:0\n",
      "  %20 : int = prim::Constant[value=1]() # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:342:0\n",
      "  %input : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::add(%input.9, %107, %20) # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/modules/transformer.py:342:0\n",
      "  %108 : bool = prim::Constant[value=1](), scope: __module.norm2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %109 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.norm2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %110 : int = prim::Constant[value=512](), scope: __module.norm2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%norm2)\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%norm2)\n",
      "  %113 : int[] = prim::ListConstruct(%110), scope: __module.norm2\n",
      "  %114 : Float(10, 32, 512, strides=[16384, 512, 1], requires_grad=1, device=cpu) = aten::layer_norm(%input, %113, %weight, %bias, %109, %108), scope: __module.norm2 # /home/theotime/.local/lib/python3.10/site-packages/torch/nn/functional.py:2484:0\n",
      "  return (%114)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(jit_tf.inlined_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff4f08-b017-4dce-a629-1efe7855b237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3641b530204edd14ed1d38eb0812d9a3d1603c19c1afb0f03cf097d4da1c7cbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
